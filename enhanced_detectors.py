"import json\nimport os\nimport re\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional\n\nimport re\n\nfrom utils import shannon_entropy, clamp_span\n\n# Enhanced context words regex to catch more secret-related terms\nCONTEXT_WORDS = re.compile(r\"(?i)(secret|token|key|apikey|api_key|password|passwd|pwd|authorization|bearer|client_secret|auth|credential|login|pin|passphrase|signature)\")\n\n# Enhanced regex to detect potential secrets with spaces or formatting\nENHANCED_SECRET_PATTERNS = [\n    re.compile(r\"(?i)(?:secret|token|key|password|pwd|pass)\\s*[:\\-]?\\s*[\\\"']?([A-Za-z0-9_\\-+/=]{8,})[\\\"']?\", re.IGNORECASE),\n    re.compile(r\"(?i)(?:sk|pk|ak|sk-|pk-|ak-)[A-Za-z0-9_\\-+/=]{10,}\", re.IGNORECASE),\n    re.compile(r\"(?i)(?:[a-z]{2,}_)?(?:api[_-]?)?(?:secret|key)[_-]?(?:key)?\\s*[:\\-]?\\s*[\\\"']?([A-Za-z0-9_\\-+/=]{15,})[\\\"']?\", re.IGNORECASE)\n]\n\nclass SecretsDetector:\n    def __init__(self, patterns_dir: str,\n                 enable_regex: bool = True,\n                 enable_entropy: bool = True,\n                 enable_context: bool = True,\n                 enable_enhanced: bool = True,  # New feature\n                 entropy_threshold: float = 3.5,  # Lowered threshold for better detection\n                 min_token_len: int = 15,  # Reduced minimum length\n                 context_window_chars: int = 50):  # Increased context window\n        self.enable_regex = enable_regex\n        self.enable_entropy = enable_entropy\n        self.enable_context = enable_context\n        self.enable_enhanced = enable_enhanced  # New parameter\n        self.entropy_threshold = entropy_threshold\n        self.min_token_len = min_token_len\n        self.context_window_chars = context_window_chars\n\n        self.signatures: List[Dict[str, Any]] = []\n        self._load_patterns(patterns_dir)\n        self._compile()\n\n    def _load_patterns(self, patterns_dir: str):\n        p = Path(patterns_dir) / \"signatures.json\"\n        if not p.exists():\n            raise FileNotFoundError(f\"patterns file not found: {p}\")\n        self.signatures = json.loads(p.read_text())\n\n    def _compile(self):\n        for s in self.signatures:\n            if s.get(\"type\") == \"regex\":\n                s[\"_re\"] = re.compile(s[\"pattern\"])\n\n    def regex_scan(self, text: str, categories: Optional[List[str]] = None) -> List[Dict[str, Any]]:\n        if not self.enable_regex:\n            return []\n        cats = {c.upper() for c in categories} if categories else None\n        matches = []\n        for sig in self.signatures:\n            if sig.get(\"type\") != \"regex\":\n                continue\n            if cats and sig[\"category\"].upper() not in cats:\n                continue\n            rx = sig.get(\"_re\")\n            if not rx:\n                continue\n            for m in re.finditer(rx, text):\n                s, e = m.span()\n                n = len(text)\n                s, e = clamp_span(s, e, n)\n                snippet = text[max(0, s-16):min(n, e+16)]\n                matches.append({\n                    \"engine\": \"regex\",\n                    \"id\": sig[\"id\"],\n                    \"category\": sig[\"category\"],\n                    \"severity\": int(sig.get(\"severity\", 3)),\n                    \"value\": m.group(0),\n                    \"start\": s,\n                    \"end\": e,\n                    \"score\": 1.0,\n                    \"snippet\": snippet\n                })\n        return matches\n\n    def entropy_scan(self, text: str) -> List[Dict[str, Any]]:\n        if not self.enable_entropy:\n            return []\n        findings = []\n        # Heuristic token candidates: long base64/hex/URL-safe runs\n        # Enhanced to better handle potential secrets\n        for m in re.finditer(r\"[A-Za-z0-9_\\-+/=]{%d,}\" % self.min_token_len, text):\n            s, e = m.span()\n            token = m.group(0)\n            # ignore obvious non-secret noise (e.g., long words of letters only)\n            if not re.search(r\"[0-9/=+_-]\", token):\n                continue\n            H = shannon_entropy(token)\n            if H >= self.entropy_threshold:\n                # Context boost: look around the token for secret-ish words\n                ctx_score = 0.0\n                if self.enable_context:\n                    L = max(0, s - self.context_window_chars)\n                    R = min(len(text), e + self.context_window_chars)\n                    context = text[L:R]\n                    if CONTEXT_WORDS.search(context):\n                        ctx_score = 0.5\n                findings.append({\n                    \"engine\": \"entropy\",\n                    \"id\": \"HIGH_ENTROPY\",\n                    \"category\": \"GENERIC\",\n                    \"severity\": 4,\n                    \"value\": token,\n                    \"start\": s,\n                    \"end\": e,\n                    \"score\": float(min(1.0, (H - self.entropy_threshold) / 2.0 + ctx_score))\n                })\n        return findings\n\n    def enhanced_scan(self, text: str) -> List[Dict[str, Any]]:\n        \"\"\"New enhanced scanning method to detect secrets with spaces or formatting\"\"\"\n        if not self.enable_enhanced:\n            return []\n        \n        findings = []\n        \n        # 1. Look for common secret patterns with spaces or formatting\n        for pattern in ENHANCED_SECRET_PATTERNS:\n            for m in re.finditer(pattern, text):\n                # Get the full match and potential secret value\n                full_match = m.group(0)\n                secret_value = m.group(1) if len(m.groups()) > 0 else full_match\n                \n                # If we have a captured group, use it as the secret value\n                if len(m.groups()) > 0 and m.group(1):\n                    secret_value = m.group(1)\n                \n                s, e = m.span()\n                n = len(text)\n                s, e = clamp_span(s, e, n)\n                \n                # Calculate entropy for the potential secret\n                H = shannon_entropy(secret_value)\n                \n                # Even if entropy is low, if it matches a strong pattern, flag it\n                if H >= self.entropy_threshold * 0.7 or len(secret_value) >= self.min_token_len * 1.5:\n                    # Context check\n                    ctx_score = 0.0\n                    if self.enable_context:\n                        L = max(0, s - self.context_window_chars)\n                        R = min(len(text), e + self.context_window_chars)\n                        context = text[L:R]\n                        if CONTEXT_WORDS.search(context):\n                            ctx_score = 0.5\n                    \n                    score = float(min(1.0, (H - (self.entropy_threshold * 0.7)) / 2.0 + 0.3 + ctx_score))\n                    \n                    findings.append({\n                        \"engine\": \"enhanced\",\n                        \"id\": \"POTENTIAL_SECRET\",\n                        \"category\": \"GENERIC\",\n                        \"severity\": 3,\n                        \"value\": secret_value,\n                        \"start\": s,\n                        \"end\": e,\n                        \"score\": score\n                    })\n        \n        # 2. Look for common password patterns\n        password_patterns = [\n            (r\"(?i)(?:password|pwd|pass)\\s*[:\\-]?\\s*[\\\"']([^\\\"'\\s]{6,})[\\\"']?\", \"PASSWORD_PATTERN\"),\n            (r\"(?i)(?:key|token|secret)\\s*[:\\-]?\\s*[\\\"']([^\\\"'\\s]{8,})[\\\"']?\", \"KEY_PATTERN\")\n        ]\n        \n        for pattern, pattern_id in password_patterns:\n            for m in re.finditer(pattern, text):\n                if len(m.groups()) > 0 and m.group(1):\n                    secret_value = m.group(1)\n                    s, e = m.span(1)  # Get span of the captured group\n                    n = len(text)\n                    s, e = clamp_span(s, e, n)\n                    \n                    # Even simple passwords should be flagged\n                    findings.append({\n                        \"engine\": \"enhanced\",\n                        \"id\": pattern_id,\n                        \"category\": \"GENERIC\",\n                        \"severity\": 3,\n                        \"value\": secret_value,\n                        \"start\": s,\n                        \"end\": e,\n                        \"score\": 0.8\n                    })\n        \n        return findings\n\n    def detect(self, text: str, categories: Optional[List[str]] = None) -> List[Dict[str, Any]]:\n        out = []\n        out.extend(self.regex_scan(text, categories))\n        out.extend(self.entropy_scan(text))\n        out.extend(self.enhanced_scan(text))  # Added enhanced scanning\n        \n        # dedupe: prefer regex over others on overlap, then enhanced over entropy\n        out.sort(key=lambda x: (\n            x[\"start\"] if x.get(\"start\") is not None else 10**12,\n            -(x[\"end\"]-x[\"start\"]) if x.get(\"start\") is not None else 0,\n            0 if x[\"engine\"] == \"regex\" else (1 if x[\"engine\"] == \"enhanced\" else 2)\n        ))\n        \n        merged = []\n        used = [False] * len(out)\n        for i, a in enumerate(out):\n            if used[i]:\n                continue\n            merged.append(a)\n            if a.get(\"start\") is None:  # entropy without span shouldn't block others\n                continue\n            for j in range(i+1, len(out)):\n                b = out[j]\n                if used[j] or b.get(\"start\") is None:\n                    continue\n                if not (b[\"end\"] <= a[\"start\"] or b[\"start\"] >= a[\"end\"]):\n                    # overlap â†’ discard lower-priority engine\n                    if (a[\"engine\"] == \"regex\" and b[\"engine\"] in [\"enhanced\", \"entropy\"]) or \\\n                       (a[\"engine\"] == \"enhanced\" and b[\"engine\"] == \"entropy\"):\n                        used[j] = True\n        return merged"