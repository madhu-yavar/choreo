apiVersion: apps/v1
kind: Deployment
metadata:
  name: jailbreak-balanced-model
  namespace: z-grid
  labels:
    app: jailbreak-balanced-model
    version: balanced-v1
spec:
  replicas: 2
  selector:
    matchLabels:
      app: jailbreak-balanced-model
  template:
    metadata:
      labels:
        app: jailbreak-balanced-model
        version: balanced-v1
    spec:
      containers:
      - name: balanced-detector
        image: python:3.9-slim
        ports:
        - containerPort: 5003
          name: http
        env:
        - name: PORT
          value: "5003"
        - name: JAILBREAK_API_KEYS
          value: "supersecret123,jailvalyavar,production-key"
        - name: BALANCED_MODEL_PATH
          value: "/model_volume/jailbreak_model_balanced/checkpoint-444"
        - name: TOKENIZER_NAME
          value: "distilbert-base-uncased"
        - name: CONFIDENCE_THRESHOLD
          value: "0.5"
        - name: MAX_SEQUENCE_LENGTH
          value: "512"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        - name: model-volume
          mountPath: /model_volume
          readOnly: true
        - name: config-volume
          mountPath: /app/deployment_model_info.json
          subPath: deployment_model_info.json
        command:
        - /bin/bash
        - -c
        - |
          set -e
          echo "üöÄ Starting Balanced Jailbreak Detection Service (94.5% accuracy, 52.9%/47.1% balanced)"

          # Install dependencies
          pip install torch==1.13.1 transformers==4.43.0 flask==2.3.3

          # Create app directory
          mkdir -p /app
          cd /app

          # Copy our balanced service code
          echo "Creating balanced jailbreak service..."
          cat > jailbreak_service_balanced.py << 'EOF'
          #!/usr/bin/env python3
          """
          Balanced Jailbreak Detection Service
          Uses the balanced DistilBERT model trained on 52.9%/47.1% jailbreak/benign data
          """

          import os
          import torch
          import logging
          import json
          from datetime import datetime
          from flask import Flask, request, jsonify
          from transformers import AutoTokenizer, AutoModelForSequenceClassification
          from typing import Dict

          # Configure logging
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)

          app = Flask(__name__)

          # API Configuration
          API_KEYS = os.environ.get('JAILBREAK_API_KEYS', 'supersecret123,jailvalyavar').split(',')

          # Model configuration
          MODEL_PATH = os.environ.get('BALANCED_MODEL_PATH', './jailbreak_model_balanced/checkpoint-444')
          TOKENIZER_NAME = os.environ.get('TOKENIZER_NAME', 'distilbert-base-uncased')
          CONFIDENCE_THRESHOLD = float(os.environ.get('CONFIDENCE_THRESHOLD', '0.5'))
          MAX_SEQUENCE_LENGTH = int(os.environ.get('MAX_SEQUENCE_LENGTH', '512'))

          # Global variables for model
          model = None
          tokenizer = None

          def authenticate_request(request):
              """Authenticate API request"""
              api_key = request.headers.get('X-API-Key')
              return api_key in API_KEYS

          def load_balanced_model():
              """Load the balanced DistilBERT model"""
              global model, tokenizer
              try:
                  logger.info(f"Loading balanced model from: {MODEL_PATH}")
                  logger.info(f"Loading tokenizer: {TOKENIZER_NAME}")

                  # Load tokenizer (will download if not in cache)
                  tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)

                  # Load our trained model
                  model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
                  model.eval()

                  if torch.cuda.is_available():
                      model = model.cuda()
                      logger.info("Using GPU for inference")
                  else:
                      logger.info("Using CPU for inference")

                  logger.info("‚úÖ Balanced model loaded successfully!")
                  return True

              except Exception as e:
                  logger.error(f"‚ùå Error loading balanced model: {e}")
                  return False

          def predict_jailbreak(text: str) -> Dict:
              """Make prediction using the balanced model"""
              try:
                  # Tokenize input
                  inputs = tokenizer(
                      text,
                      return_tensors='pt',
                      truncation=True,
                      padding=True,
                      max_length=MAX_SEQUENCE_LENGTH
                  )

                  # Move to GPU if available
                  if torch.cuda.is_available():
                      inputs = {k: v.cuda() for k, v in inputs.items()}

                  # Make prediction
                  with torch.no_grad():
                      outputs = model(**inputs)
                      probs = torch.softmax(outputs.logits, dim=-1)

                  # Extract probabilities
                  jailbreak_prob = probs[0][1].item() if probs.shape[0] > 1 else probs[1].item()
                  benign_prob = probs[0][0].item() if probs.shape[0] > 1 else probs[0].item()

                  # Determine prediction
                  prediction = "jailbreak" if jailbreak_prob > CONFIDENCE_THRESHOLD else "benign"
                  confidence = max(jailbreak_prob, benign_prob)

                  return {
                      "text": text,
                      "prediction": prediction,
                      "confidence": round(confidence, 4),
                      "probabilities": {
                          "benign": round(benign_prob, 4),
                          "jailbreak": round(jailbreak_prob, 4)
                      },
                      "threshold_used": CONFIDENCE_THRESHOLD,
                      "model_type": "balanced_distilbert",
                      "timestamp": datetime.now().isoformat()
                  }

              except Exception as e:
                  logger.error(f"Error making prediction: {e}")
                  return {
                      "text": text,
                      "prediction": "error",
                      "confidence": 0.0,
                      "error": str(e),
                      "model_type": "balanced_distilbert",
                      "timestamp": datetime.now().isoformat()
                  }

          @app.route('/health', methods=['GET'])
          def health_check():
              """Health check endpoint"""
              status = "healthy" if model is not None else "unhealthy"
              model_loaded = model is not None

              return jsonify({
                  "status": status,
                  "model_loaded": model_loaded,
                  "model_type": "balanced_distilbert" if model_loaded else None,
                  "timestamp": datetime.now().isoformat()
              })

          @app.route('/detect', methods=['POST'])
          def detect_jailbreak():
              """Main detection endpoint"""
              if not authenticate_request(request):
                  return jsonify({"error": "Unauthorized"}), 401

              if model is None:
                  return jsonify({"error": "Model not loaded"}), 503

              try:
                  data = request.get_json()
                  if not data or 'text' not in data:
                      return jsonify({"error": "Missing 'text' field in request"}), 400

                  text = data['text']
                  if not isinstance(text, str) or not text.strip():
                      return jsonify({"error": "Invalid text input"}), 400

                  # Make prediction
                  result = predict_jailbreak(text)

                  # Add request metadata
                  result["request_id"] = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(text) % 10000:04d}"

                  return jsonify(result)

              except Exception as e:
                  logger.error(f"Error in detect_jailbreak: {e}")
                  return jsonify({"error": f"Internal server error: {str(e)}"}), 500

          if __name__ == '__main__':
              logger.info("üöÄ Starting Balanced Jailbreak Detection Service")

              # Load model
              if load_balanced_model():
                  logger.info("‚úÖ Service ready to handle requests")
              else:
                  logger.error("‚ùå Failed to load model - service will start but cannot process requests")

              # Start Flask app
              port = int(os.environ.get('PORT', 5000))
              app.run(host='0.0.0.0', port=port, debug=False)
          EOF

          echo "‚úÖ Starting balanced jailbreak detection service..."
          python jailbreak_service_balanced.py

        livenessProbe:
          httpGet:
            path: /health
            port: 5003
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 5003
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: model-volume
        persistentVolumeClaim:
          claimName: balanced-model-pvc
      - name: config-volume
        configMap:
          name: balanced-model-config
---
apiVersion: v1
kind: Service
metadata:
  name: jailbreak-balanced-service
  namespace: z-grid
  labels:
    app: jailbreak-balanced-model
spec:
  type: ClusterIP
  ports:
  - port: 5003
    targetPort: 5003
    protocol: TCP
    name: http
  selector:
    app: jailbreak-balanced-model
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: balanced-model-config
  namespace: z-grid
data:
  deployment_model_info.json: |
    {
      "model_info": {
        "name": "balanced-distilbert-jailbreak-detector",
        "base_model": "distilbert-base-uncased",
        "training_dataset": "jailbreak_dataset_perfectly_balanced_final.json",
        "dataset_balance": {
          "total_examples": 1699,
          "jailbreak": 899,
          "benign": 800,
          "jailbreak_percentage": 52.9,
          "benign_percentage": 47.1
        },
        "performance": {
          "best_epoch": 10.67,
          "final_accuracy": 0.945,
          "final_f1": 0.947,
          "final_precision": 0.969,
          "final_recall": 0.926
        },
        "training_config": {
          "epochs": 12,
          "batch_size": 16,
          "learning_rate": 3e-5,
          "eval_steps": 100,
          "early_stopping_patience": 3
        },
        "deployment": {
          "model_path": "./jailbreak_model_balanced/checkpoint-444",
          "tokenizer_path": "distilbert-base-uncased",
          "confidence_threshold": 0.5,
          "version": "balanced-v1"
        }
      }
    }