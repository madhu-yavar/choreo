apiVersion: batch/v1
kind: Job
metadata:
  name: simple-log-collector-job
  namespace: z-grid
spec:
  backoffLimit: 3
  template:
    spec:
      serviceAccountName: log-collector-sa
      containers:
      - name: log-collector
        image: bitnami/kubectl:latest
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        command: ["/bin/sh"]
        args: ["-c"]
        script: |
          echo "Starting Z-Grid Log Collector..."

          # Install Python
          apt-get update > /dev/null 2>&1
          apt-get install -y python3 python3-pip > /dev/null 2>&1

          # Install required Python packages
          pip3 install requests > /dev/null 2>&1

          python3 -c "
import subprocess
import json
import re
import time
from datetime import datetime

def collect_logs_from_pod(pod_name):
    '''Collect logs from a specific pod'''
    try:
        cmd = ['kubectl', 'logs', '-n', 'z-grid', '--since=2m', pod_name]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)

        if result.returncode == 0:
            return result.stdout.strip().split('\\n')
        return []
    except Exception as e:
        print(f'Error collecting from {pod_name}: {e}')
        return []

def parse_access_log(log_line):
    '''Parse access log format'''
    # Pattern: 'IP - - [timestamp] \"METHOD endpoint HTTP/1.1\" status_code'
    match = re.search(r'(\\d+\\.\\d+\\.\\d+\\.\\d+).*?\"(\\w+)\\s+([^\\s]+).*?\"\\s+(\\d+)', log_line)
    if match:
        return {
            'client_ip': match.group(1),
            'method': match.group(2),
            'endpoint': match.group(3),
            'status_code': int(match.group(4))
        }
    return None

def insert_into_database(pod_name, requests):
    '''Insert requests into SQLite database'''
    try:
        # Use sqlite3 command line tool
        insert_cmd = '''
        sqlite3 /app/database/zgrid_monitoring.db << EOF
        '''

        for req in requests:
            service_name = pod_name.split('-')[0] if '-' in pod_name else pod_name

            # Realistic response times based on request type
            if req['method'] == 'POST' and req['endpoint'] == '/validate':
                response_time = 70000  # 70 seconds for ML processing
            elif req['method'] == 'GET' and req['endpoint'] == '/health':
                response_time = 50      # 50ms for health checks
            else:
                response_time = 1000   # Default 1 second

            insert_cmd += f'''
            INSERT INTO request_history (service_name, method, endpoint, status_code, response_time, client_ip, timestamp)
            VALUES ('{service_name}', '{req['method']}', '{req['endpoint']}', {req['status_code']}, {response_time}, '{req['client_ip']}', datetime('now'));
            '''

        insert_cmd += 'EOF\\n'

        # Execute the insertion
        result = subprocess.run(insert_cmd, shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print(f'Successfully inserted {len(requests)} requests from {pod_name}')
            return True
        else:
            print(f'Error inserting from {pod_name}: {result.stderr}')
            return False

    except Exception as e:
        print(f'Database insertion error: {e}')
        return False

def main():
    '''Main log collection loop'''
    print('Starting log collection cycle...')

    # Get target pods
    cmd = ['kubectl', 'get', 'pods', '-n', 'z-grid', '-o', 'json']
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)

    if result.returncode != 0:
        print('Failed to get pods')
        return

    pods_data = json.loads(result.stdout)
    target_pods = ['bias-deberta-v3', 'gateway-v2', 'tox-service']

    total_requests = 0

    for pod in pods_data.get('items', []):
        pod_name = pod['metadata']['name']

        # Skip monitoring pods
        if any(skip in pod_name for skip in ['monitoring', 'dashboard', 'sqlite', 'log-collector']):
            continue

        # Only collect from target pods
        if not any(target in pod_name for target in target_pods):
            continue

        # Collect logs
        logs = collect_logs_from_pod(pod_name)
        parsed_requests = []

        for log_line in logs:
            parsed = parse_access_log(log_line)
            if parsed and (parsed['endpoint'] in ['/validate', '/health']):
                parsed_requests.append(parsed)

        # Insert into database
        if parsed_requests:
            insert_into_database(pod_name, parsed_requests)
            total_requests += len(parsed_requests)

    print(f'Collection complete. Total requests processed: {total_requests}')

# Run collection
main()
          "
        volumeMounts:
        - name: database-storage
          mountPath: /app/database
      restartPolicy: Never
      volumes:
      - name: database-storage
        persistentVolumeClaim:
          claimName: sqlite-pvc